{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5de89f",
   "metadata": {},
   "source": [
    "# Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce9c569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "root = Path.cwd().parent\n",
    "sys.path.append(str(root))\n",
    "plt.rcParams.update({\"text.usetex\": True, \"font.family\": \"Computer Modern\"}) \n",
    "from src.utils.time import hhmmss_to_seconds\n",
    "\n",
    "root = Path.cwd().parent\n",
    "sys.path.append(str(root))\n",
    "plt.rcParams.update({\"text.usetex\": True, \"font.family\": \"Computer Modern\"}) \n",
    "\n",
    "parent = Path('..','data')\n",
    "dynamic_path = parent / 'dynamic_gtfs'\n",
    "static_path = parent / 'static_gtfs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad7ddf",
   "metadata": {},
   "source": [
    "# Load static GTFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba64d008",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m stops \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(static_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstops.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m shapes \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(static_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshapes.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m stop_times \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatic_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstop_times.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m stop_times[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrival_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stop_times[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrival_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(hhmmss_to_seconds)\n\u001b[1;32m      7\u001b[0m stop_times[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeparture_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stop_times[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeparture_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(hhmmss_to_seconds)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[0;32mparsers.pyx:820\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:914\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "routes = pd.read_csv(static_path / 'routes.txt', sep=',', low_memory=False)\n",
    "trips = pd.read_csv(static_path / 'trips.txt', sep=',', low_memory=False)\n",
    "stops = pd.read_csv(static_path / 'stops.txt', sep=',', low_memory=False)\n",
    "shapes = pd.read_csv(static_path / 'shapes.txt', sep=',', low_memory=False)\n",
    "stop_times = pd.read_csv(static_path / 'stop_times.txt', sep=',', low_memory=False)\n",
    "stop_times['arrival_time'] = stop_times['arrival_time'].apply(hhmmss_to_seconds)\n",
    "stop_times['departure_time'] = stop_times['departure_time'].apply(hhmmss_to_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae3066",
   "metadata": {},
   "source": [
    "# Filtering static data (just buses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db72a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_route_ids = list(routes[routes['route_type'] == 3]['route_id'].unique())\n",
    "bus_trip_ids  = list(trips[trips['route_id'].isin(bus_route_ids)]['trip_id'].unique())\n",
    "bus_shape_ids = list(trips[trips['route_id'].isin(bus_route_ids)]['shape_id'].unique())\n",
    "bus_stop_ids = list(stop_times[stop_times['trip_id'].isin(bus_trip_ids)]['stop_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeceb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_lens = {\n",
    "    'routes': len(routes), \n",
    "    'trips': len(trips), \n",
    "    'shapes': len(shapes), \n",
    "    'stops': len(stops),\n",
    "    'stop_times': len(stop_times), \n",
    "}\n",
    "\n",
    "routes = routes[routes['route_id'].isin(bus_route_ids)]\n",
    "trips = trips[trips['trip_id'].isin(bus_trip_ids)]\n",
    "shapes = shapes[shapes['shape_id'].isin(bus_shape_ids)]\n",
    "stops = stops[stops['stop_id'].isin(bus_stop_ids)]\n",
    "stop_times = stop_times[stop_times['trip_id'].isin(bus_trip_ids)]\n",
    "\n",
    "filtered_lens = {\n",
    "    'routes': len(routes), \n",
    "    'trips': len(trips), \n",
    "    'shapes': len(shapes), \n",
    "    'stops': len(stops),\n",
    "    'stop_times': len(stop_times), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5a32b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table          Before    After     Diff\n",
      "------------------------------------\n",
      "routes            367      303       64\n",
      "trips          260366   175048    85318\n",
      "shapes         631719   485517   146202\n",
      "stops            6181     4501     1680\n",
      "stop_times    5326956  3693058  1633898\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Table':<12} {'Before':>8} {'After':>8} {'Diff':>8}\")\n",
    "print(\"-\" * 36)\n",
    "for table in prev_lens:\n",
    "    before = prev_lens[table]\n",
    "    after = filtered_lens[table]\n",
    "    diff = before - after\n",
    "    print(f\"{table:<12} {before:>8} {after:>8} {diff:>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f32888",
   "metadata": {},
   "source": [
    "# Graph construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c634d27",
   "metadata": {},
   "source": [
    "### Plot map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b893273",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(16,9), dpi=450, facecolor='black')\n",
    "ax.set_facecolor('black')\n",
    "\n",
    "ax.scatter(stops['stop_lon'], stops['stop_lat'], s=2, c='white', alpha=0.7)\n",
    "for _, group in shapes.groupby(\"shape_id\"):\n",
    "    group = group.sort_values(\"shape_pt_sequence\")\n",
    "    ax.plot(group[\"shape_pt_lon\"], group[\"shape_pt_lat\"], linewidth=0.3, c='white')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "fig.savefig('graph.png', facecolor=fig.get_facecolor())\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958f548",
   "metadata": {},
   "source": [
    "### Construct graph from constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "490e30f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neceessary rows\n",
    "tmp = stop_times.copy()\n",
    "tmp = tmp[tmp['stop_headsign'].notna() & (tmp['stop_headsign'] != \"\")]\n",
    "tmp = stop_times[['trip_id','stop_id','arrival_time','departure_time','stop_sequence','shape_dist_traveled']].copy()\n",
    "tmp = tmp.sort_values(['trip_id', 'stop_sequence']).copy()\n",
    "\n",
    "# Next stop and arrival time\n",
    "tmp['next_stop'] = tmp.groupby('trip_id')['stop_id'].shift(-1)\n",
    "tmp['next_arrival_time'] = tmp.groupby('trip_id')['arrival_time'].shift(-1)\n",
    "tmp['next_shape_dist'] = tmp.groupby('trip_id')['shape_dist_traveled'].shift(-1)\n",
    "\n",
    "# Travel time and distance until the next stop\n",
    "tmp['dt'] = tmp['next_arrival_time'] - tmp['departure_time']\n",
    "tmp['ds'] = tmp['next_shape_dist'] - tmp['shape_dist_traveled']\n",
    "\n",
    "# Drop invalid rows, and rename the cols\n",
    "tmp = tmp.dropna(subset=['next_stop', 'dt'])[['stop_id', 'next_stop', 'dt', 'ds']]\n",
    "tmp = tmp.rename(columns={'stop_id': 'src', 'next_stop': 'dst'})\n",
    "\n",
    "# Edges: average travel time between nodes\n",
    "edges = tmp.groupby(['src', 'dst'], as_index=False).agg({\n",
    "    'dt': 'mean',\n",
    "    'ds': 'mean'\n",
    "})\n",
    "del tmp\n",
    "\n",
    "# Nodes: stops\n",
    "nodes = stops[['stop_id','stop_lat','stop_lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5c0b4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), set())"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the filtering\n",
    "nodes_of_edges = set(pd.concat([edges['src'], edges['dst']]).unique())\n",
    "nodes_itself = set(nodes['stop_id'])\n",
    "nodes_of_edges - nodes_itself, nodes_itself - nodes_of_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fb8d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.to_csv(parent / \"graphs\" / \"edges.csv\", index=False)\n",
    "nodes.to_csv(parent / \"graphs\" / \"nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65235e",
   "metadata": {},
   "source": [
    "### Find edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv(parent / \"graphs\" / \"edges.csv\")\n",
    "nodes = pd.read_csv(parent / \"graphs\" / \"nodes.csv\")\n",
    "display(edges.head(4))\n",
    "display(nodes.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3addec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "# Add edges with weight\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['src'], row['dst'], weight=row['travel_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b190ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(height=\"800px\", width=\"100%\", directed=True)\n",
    "net.from_nx(G)\n",
    "\n",
    "# Disable labels\n",
    "for node in net.nodes:\n",
    "    node[\"label\"] = \"\"\n",
    "    \n",
    "net.save_graph(\"large_graph.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
