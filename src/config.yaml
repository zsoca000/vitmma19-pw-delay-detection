training:
  batch_size: 64
  lr: 0.001
  patience: 3

num_epochs: 15

model:
  in_dim: 7
  gcn_dims: [16,16]
  edge_attr_dim: 2
  embd_dim: 8
  mlp_dims: [32,16]
  out_dim: 1