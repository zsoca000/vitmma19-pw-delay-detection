{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2bb8d3",
   "metadata": {},
   "source": [
    "### Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from utils.time import name_to_day\n",
    "from data_processing import (\n",
    "    load_train_test_split,\n",
    "    load_graph,\n",
    "    load_delays,\n",
    "    load_stop_id_to_idx,\n",
    "    load_trip_idx_list\n",
    ")\n",
    "root = Path('/mnt/c/Users/rdsup/Desktop/vitmma19-pw-delay-detection')\n",
    "\n",
    "data_path = root / 'data'\n",
    "delays_path = data_path / 'delays'\n",
    "graphs_path = data_path / 'graphs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b6fca",
   "metadata": {},
   "source": [
    "### Calc scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "47a67608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "graphs_train, delays_train = [],[]\n",
    "records = load_train_test_split(data_path)\n",
    "for record_name in tqdm(records['train']):\n",
    "    for load_path in (graphs_path / record_name).iterdir():\n",
    "        graphs_train.append(torch.load(load_path, weights_only=False))\n",
    "        \n",
    "    delays_train.append(load_delays(record_name,delays_path)['delay'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e7539c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all scalers to /mnt/c/Users/rdsup/Desktop/vitmma19-pw-delay-detection/data/scalers.pkl\n"
     ]
    }
   ],
   "source": [
    "def save_all_scalers(graphs, delays, data_path:Path):\n",
    "    # Node features\n",
    "    all_nodes = np.vstack([g.x.numpy() for g in graphs])\n",
    "    scaler_node = StandardScaler()\n",
    "    scaler_node.fit(all_nodes)\n",
    "    \n",
    "    # Edge features\n",
    "    all_edges = np.vstack([g.edge_attr.numpy() for g in graphs])\n",
    "    scaler_edge = StandardScaler()\n",
    "    scaler_edge.fit(all_edges)\n",
    "\n",
    "    # Delay features\n",
    "    scaler_delay = StandardScaler()\n",
    "    scaler_delay.fit(np.concatenate(delays).reshape(-1,1))\n",
    "\n",
    "    # Combine into a dictionary\n",
    "    scalers = {\n",
    "        'node': scaler_node,\n",
    "        'edge': scaler_edge,\n",
    "        'delay': scaler_delay,\n",
    "    }\n",
    "\n",
    "    # Save everything\n",
    "    joblib.dump(scalers, data_path / 'scalers.pkl')\n",
    "    print(f\"Saved all scalers to {data_path / 'scalers.pkl'}\")\n",
    "\n",
    "def load_all_scalers(data_path):\n",
    "    scalers =  joblib.load(data_path / 'scalers.pkl')\n",
    "    scalers['day'] = lambda x: 2*(x/6)-1\n",
    "    scalers['sec'] = lambda x: 2*(x/(24*3600))-1\n",
    "    return scalers\n",
    "\n",
    "save_all_scalers(graphs_train, delays_train, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_idx_list = load_trip_idx_list(graphs_path)\n",
    "records = load_train_test_split(data_path)\n",
    "\n",
    "record_name = '20251009'\n",
    "day = name_to_day(record_name)[0] # 0-6 TODO: tensor\n",
    "df = load_delays(record_name,delays_path)\n",
    "\n",
    "trip_id_list = df.index.to_numpy()\n",
    "sec_list = torch.tensor(df['trip_start'].to_numpy(),dtype=torch.float32)\n",
    "day_list = torch.ones_like(sec_list,dtype=torch.float32)*day\n",
    "delay_list = torch.tensor(df['delay'].to_numpy(),dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            if i < len(layer_sizes)-2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431396a",
   "metadata": {},
   "source": [
    "### Mini batches (PyG flattens...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "batch_size = 32\n",
    "\n",
    "day_batch = torch.zeros((batch_size,1), dtype=torch.float)\n",
    "sec_batch = torch.zeros((batch_size,1), dtype=torch.float)\n",
    "graphs_batch = []\n",
    "trip_idx_batch = []\n",
    "delay_batch = torch.zeros((batch_size,1), dtype=torch.float)\n",
    "\n",
    "for trip_id, row in df.iterrows():\n",
    "    route_id, delay, sec = row\n",
    "    \n",
    "    try:\n",
    "        g = load_graph(sec, 1/2, record_name, graphs_path)\n",
    "    except FileNotFoundError:\n",
    "        # print(f\"Graph not found for trip {trip_id}, sec {sec}\")\n",
    "        continue\n",
    "    \n",
    "    graphs_batch.append(g)\n",
    "    day_batch[i,0] = day\n",
    "    sec_batch[i,0] = sec\n",
    "    trip_idx_batch.append(trip_idx_list[trip_id])\n",
    "    delay_batch[i,0] = delay\n",
    "    i += 1\n",
    "    \n",
    "    # If batch is full, stop loading\n",
    "    if i == batch_size:\n",
    "        graphs_batch = Batch.from_data_list(graphs_batch)\n",
    "        break\n",
    "\n",
    "# Now you have your batch:\n",
    "# graphs_batch, day_batch, sec_batch, trip_delay, delay_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "114f35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNWithEdge(nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int], edge_attr_dim: int):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            nn_edge = nn.Sequential(\n",
    "                nn.Linear(edge_attr_dim, layer_sizes[i]*layer_sizes[i+1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_sizes[i]*layer_sizes[i+1], layer_sizes[i]*layer_sizes[i+1])\n",
    "            )\n",
    "            self.convs.append(NNConv(layer_sizes[i], layer_sizes[i+1], nn_edge, aggr='mean'))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6912a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([144032, 8])\n",
      "torch.Size([32, 8])\n"
     ]
    }
   ],
   "source": [
    "x = graphs_batch.x\n",
    "edge_index = graphs_batch.edge_index\n",
    "edge_attr = graphs_batch.edge_attr\n",
    "trip_nodes = trip_idx_batch\n",
    "day = day_batch\n",
    "sec = sec_batch\n",
    "\n",
    "\n",
    "gcn = GCNWithEdge(layer_sizes=[7,8,8],edge_attr_dim=2)\n",
    "mlp = MLP(layer_sizes=[8+2,4,1])\n",
    "\n",
    "x = gcn(graphs_batch.x, graphs_batch.edge_index, graphs_batch.edge_attr)\n",
    "print(x.shape)\n",
    "\n",
    "trip_embeddings = []\n",
    "for nodes in trip_nodes:\n",
    "    # nodes_in_trip contains **indices relative to x**, e.g., [12, 45, 78]\n",
    "    x_trip = x[nodes]  # select the embeddings for this trip\n",
    "    x_trip = x_trip.mean(dim=0)  # or .sum(dim=0), or torch.max(dim=0)\n",
    "    trip_embeddings.append(x_trip)\n",
    "\n",
    "# Stack to [num_trips, embedding_dim]\n",
    "x = torch.stack(trip_embeddings, dim=0)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndOfTripDelay(nn.Module):\n",
    "    def __init__(self, gcn_layers: list[int], edge_attr_dim: int, mlp_layers: list[int]):\n",
    "        super().__init__()\n",
    "        self.GCN = GCNWithEdge(gcn_layers, edge_attr_dim)\n",
    "        self.MLP = MLP(mlp_layers)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, trip_nodes, day, sec):\n",
    "\n",
    "        # GCN\n",
    "        x = self.GCN(x, edge_index, edge_attr)\n",
    "\n",
    "        trip_embeddings = []\n",
    "        for nodes in trip_nodes:\n",
    "            # nodes_in_trip contains **indices relative to x**, e.g., [12, 45, 78]\n",
    "            x = x[nodes]  # select the embeddings for this trip\n",
    "            x = x.mean(dim=0)  # or .sum(dim=0), or torch.max(dim=0)\n",
    "            trip_embeddings.append(x)\n",
    "\n",
    "        # Stack to [num_trips, embedding_dim]\n",
    "        x = torch.stack(trip_embeddings, dim=0)\n",
    "\n",
    "        # Add day/hour info\n",
    "        graph_emb = torch.cat([x, day, sec], dim=1)\n",
    "\n",
    "        # MLP for prediction\n",
    "        pred = self.MLP(graph_emb)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65894f",
   "metadata": {},
   "source": [
    "### Without minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3d1b2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNWithEdge(nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int], edge_attr_dim: int):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            nn_edge = nn.Sequential(\n",
    "                nn.Linear(edge_attr_dim, layer_sizes[i]*layer_sizes[i+1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_sizes[i]*layer_sizes[i+1], layer_sizes[i]*layer_sizes[i+1])\n",
    "            )\n",
    "            self.convs.append(NNConv(layer_sizes[i], layer_sizes[i+1], nn_edge, aggr='mean'))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class EndOfTripDelay(nn.Module):\n",
    "    def __init__(self, \n",
    "            in_dim: int, \n",
    "            gcn_dims:list[int], edge_attr_dim: int, \n",
    "            embd_dim: int,\n",
    "            mlp_dims: list[int],\n",
    "            out_dim: int,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.GCN = GCNWithEdge(\n",
    "            [in_dim] + gcn_dims + [embd_dim], \n",
    "            edge_attr_dim\n",
    "        )\n",
    "        \n",
    "        self.MLP = MLP(\n",
    "            [embd_dim + 2] + mlp_dims + [out_dim]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, trip_nodes, day, sec):\n",
    "\n",
    "        # GCN\n",
    "        x = self.GCN(x, edge_index, edge_attr)\n",
    "\n",
    "        # Average trip pooling\n",
    "        x = x[trip_nodes].mean(dim=0)\n",
    "\n",
    "        # Meta embedding\n",
    "        x = torch.cat([x, day, sec])\n",
    "\n",
    "        # MLP for prediction\n",
    "        x = self.MLP(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = load_all_scalers(data_path)\n",
    "\n",
    "scaler_node = scalers['node']\n",
    "scaler_edge = scalers['edge']\n",
    "scaler_delay = scalers['delay']\n",
    "scaler_day = scalers['day']\n",
    "scaler_sec = scalers['sec']\n",
    "\n",
    "#########--ITER--##########\n",
    "i = 5\n",
    "trip_id = trip_id_list[i]\n",
    "###########################\n",
    "\n",
    "day = day_list[i].unsqueeze(0)\n",
    "sec = sec_list[i].unsqueeze(0)\n",
    "try:\n",
    "    g = load_graph(sec, 1/2, record_name, graphs_path)\n",
    "    g.edge_attr.detach() # Static edges right now\n",
    "    trip_nodes = trip_idx_list[trip_id]\n",
    "except:\n",
    "    pass # continue\n",
    "\n",
    "model = EndOfTripDelay(\n",
    "    in_dim=7,gcn_dims=[32],edge_attr_dim=2,embd_dim=16,mlp_dims=[2],out_dim=1\n",
    ")\n",
    "\n",
    "\n",
    "x = scaler_node.transform(g.x)\n",
    "edge_attr = scaler_edge.transform(g.edge_attr)\n",
    "day = scaler_day(day)\n",
    "sec = scaler_sec(sec)\n",
    "\n",
    "delay = scaler_delay\n",
    "\n",
    "model(x,g.edge_index,edge_attr, trip_nodes, day, sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8998fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
