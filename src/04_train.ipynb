{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2bb8d3",
   "metadata": {},
   "source": [
    "# Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4394847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from utils.time import name_to_day\n",
    "from data_processing import (\n",
    "    load_train_test_split,\n",
    "    load_graph,\n",
    "    load_delays,\n",
    "    load_stop_id_to_idx,\n",
    "    load_trip_idx_list,\n",
    "    available_bin_codes\n",
    ")\n",
    "\n",
    "from train import (\n",
    "    load_scalers, \n",
    "    load_train_data\n",
    ")\n",
    "root = Path('/mnt/c/Users/rdsup/Desktop/vitmma19-pw-delay-detection')\n",
    "\n",
    "data_path = root / 'data'\n",
    "delays_path = data_path / 'delays'\n",
    "graphs_path = data_path / 'graphs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e51d6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_idx_list = load_trip_idx_list(graphs_path)\n",
    "records = load_train_test_split(data_path)\n",
    "\n",
    "record_name = '20251011'\n",
    "day = name_to_day(record_name)[0] # 0-6 TODO: tensor\n",
    "df = load_delays(record_name,delays_path)\n",
    "bin_codes = available_bin_codes(record_name, graphs_path)\n",
    "\n",
    "dt = 1/2\n",
    "bins = np.arange(0,24+dt,dt)\n",
    "bins *= 60*60\n",
    "\n",
    "df['bin'] = pd.cut(df['trip_start'], bins=bins, right=False)\n",
    "df['bin_code'] = df['bin'].cat.codes\n",
    "df = df[df['bin_code'].isin(bin_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b27f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_id_list = df.index.to_numpy()\n",
    "sec_list = torch.tensor(df['trip_start'].to_numpy(),dtype=torch.float32)\n",
    "day_list = torch.ones_like(sec_list,dtype=torch.float32)*day\n",
    "delay_list = torch.tensor(df['delay'].to_numpy(),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c7154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:12<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    x_train, \n",
    "    edge_attr_train, \n",
    "    delays_train\n",
    ") = load_train_data(data_path)\n",
    "scalers = load_scalers(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431396a",
   "metadata": {},
   "source": [
    "### Mini batches (PyG flattens...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "batch_size = 32\n",
    "\n",
    "day_batch = torch.zeros((batch_size,1), dtype=torch.float)\n",
    "sec_batch = torch.zeros((batch_size,1), dtype=torch.float)\n",
    "graphs_batch = []\n",
    "trip_idx_batch = []\n",
    "delay_batch = torch.zeros((batch_size,1), dtype=torch.float)\n",
    "\n",
    "for trip_id, row in df.iterrows():\n",
    "    route_id, delay, sec = row\n",
    "    \n",
    "    try:\n",
    "        g = load_graph(sec, 1/2, record_name, graphs_path)\n",
    "    except FileNotFoundError:\n",
    "        # print(f\"Graph not found for trip {trip_id}, sec {sec}\")\n",
    "        continue\n",
    "    \n",
    "    graphs_batch.append(g)\n",
    "    day_batch[i,0] = day\n",
    "    sec_batch[i,0] = sec\n",
    "    trip_idx_batch.append(trip_idx_list[trip_id])\n",
    "    delay_batch[i,0] = delay\n",
    "    i += 1\n",
    "    \n",
    "    # If batch is full, stop loading\n",
    "    if i == batch_size:\n",
    "        graphs_batch = Batch.from_data_list(graphs_batch)\n",
    "        break\n",
    "\n",
    "# Now you have your batch:\n",
    "# graphs_batch, day_batch, sec_batch, trip_delay, delay_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "114f35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNWithEdge(nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int], edge_attr_dim: int):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            nn_edge = nn.Sequential(\n",
    "                nn.Linear(edge_attr_dim, layer_sizes[i]*layer_sizes[i+1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_sizes[i]*layer_sizes[i+1], layer_sizes[i]*layer_sizes[i+1])\n",
    "            )\n",
    "            self.convs.append(NNConv(layer_sizes[i], layer_sizes[i+1], nn_edge, aggr='mean'))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6912a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([144032, 8])\n",
      "torch.Size([32, 8])\n"
     ]
    }
   ],
   "source": [
    "x = graphs_batch.x\n",
    "edge_index = graphs_batch.edge_index\n",
    "edge_attr = graphs_batch.edge_attr\n",
    "trip_nodes = trip_idx_batch\n",
    "day = day_batch\n",
    "sec = sec_batch\n",
    "\n",
    "\n",
    "gcn = GCNWithEdge(layer_sizes=[7,8,8],edge_attr_dim=2)\n",
    "mlp = MLP(layer_sizes=[8+2,4,1])\n",
    "\n",
    "x = gcn(graphs_batch.x, graphs_batch.edge_index, graphs_batch.edge_attr)\n",
    "print(x.shape)\n",
    "\n",
    "trip_embeddings = []\n",
    "for nodes in trip_nodes:\n",
    "    # nodes_in_trip contains **indices relative to x**, e.g., [12, 45, 78]\n",
    "    x_trip = x[nodes]  # select the embeddings for this trip\n",
    "    x_trip = x_trip.mean(dim=0)  # or .sum(dim=0), or torch.max(dim=0)\n",
    "    trip_embeddings.append(x_trip)\n",
    "\n",
    "# Stack to [num_trips, embedding_dim]\n",
    "x = torch.stack(trip_embeddings, dim=0)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndOfTripDelay(nn.Module):\n",
    "    def __init__(self, gcn_layers: list[int], edge_attr_dim: int, mlp_layers: list[int]):\n",
    "        super().__init__()\n",
    "        self.GCN = GCNWithEdge(gcn_layers, edge_attr_dim)\n",
    "        self.MLP = MLP(mlp_layers)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, trip_nodes, day, sec):\n",
    "\n",
    "        # GCN\n",
    "        x = self.GCN(x, edge_index, edge_attr)\n",
    "\n",
    "        trip_embeddings = []\n",
    "        for nodes in trip_nodes:\n",
    "            # nodes_in_trip contains **indices relative to x**, e.g., [12, 45, 78]\n",
    "            x = x[nodes]  # select the embeddings for this trip\n",
    "            x = x.mean(dim=0)  # or .sum(dim=0), or torch.max(dim=0)\n",
    "            trip_embeddings.append(x)\n",
    "\n",
    "        # Stack to [num_trips, embedding_dim]\n",
    "        x = torch.stack(trip_embeddings, dim=0)\n",
    "\n",
    "        # Add day/hour info\n",
    "        graph_emb = torch.cat([x, day, sec], dim=1)\n",
    "\n",
    "        # MLP for prediction\n",
    "        pred = self.MLP(graph_emb)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65894f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3d1b2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            if i < len(layer_sizes)-2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class GCNWithEdge(nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int], edge_attr_dim: int):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            nn_edge = nn.Sequential(\n",
    "                nn.Linear(edge_attr_dim, layer_sizes[i]*layer_sizes[i+1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_sizes[i]*layer_sizes[i+1], layer_sizes[i]*layer_sizes[i+1])\n",
    "            )\n",
    "            self.convs.append(NNConv(layer_sizes[i], layer_sizes[i+1], nn_edge, aggr='mean'))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class EndOfTripDelay(nn.Module):\n",
    "    def __init__(self, \n",
    "            in_dim: int, \n",
    "            gcn_dims:list[int], edge_attr_dim: int, \n",
    "            embd_dim: int,\n",
    "            mlp_dims: list[int],\n",
    "            out_dim: int,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.GCN = GCNWithEdge(\n",
    "            [in_dim] + gcn_dims + [embd_dim], \n",
    "            edge_attr_dim\n",
    "        )\n",
    "        \n",
    "        self.MLP = MLP(\n",
    "            [embd_dim + 2] + mlp_dims + [out_dim]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, trip_nodes, day, sec):\n",
    "\n",
    "        # GCN\n",
    "        x = self.GCN(x, edge_index, edge_attr)\n",
    "\n",
    "        # Average trip pooling\n",
    "        x = x[trip_nodes].mean(dim=0)\n",
    "\n",
    "        # Meta embedding\n",
    "        x = torch.cat([x, day, sec])\n",
    "\n",
    "        # MLP for prediction\n",
    "        x = self.MLP(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27808f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3155], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EndOfTripDelay(\n",
    "    in_dim=7,gcn_dims=[32],edge_attr_dim=2,embd_dim=16,mlp_dims=[2],out_dim=1\n",
    ")\n",
    "\n",
    "#########--TRAIN ITER--##########\n",
    "i = 5\n",
    "trip_id = trip_id_list[i]\n",
    "###########################\n",
    "\n",
    "day = day_list[i].unsqueeze(0)\n",
    "sec = sec_list[i].unsqueeze(0)\n",
    "delay = delay_list[i].unsqueeze(0)\n",
    "try:\n",
    "    g = load_graph(sec, 1/2, record_name, graphs_path)\n",
    "    g.edge_attr.detach() # Static edges right now\n",
    "    trip_nodes = trip_idx_list[trip_id]\n",
    "except:\n",
    "    pass # continue\n",
    "\n",
    "x = scalers['x'].transform(g.x)\n",
    "edge_attr = scalers['edge_attr'].transform(g.edge_attr)\n",
    "edge_index = g.edge_index\n",
    "\n",
    "day = scalers['day'].transform(day)\n",
    "sec = scalers['sec'].transform(sec)\n",
    "delay = scalers['delay'].transform(delay)\n",
    "\n",
    "model(x, edge_index, edge_attr, trip_nodes, day, sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748df6c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b0d1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = load_train_test_split(data_path)\n",
    "record_name = '20251011'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9502e2c5",
   "metadata": {},
   "source": [
    "### Single graph in cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589bd9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, record_name, data_path:Path, scalers:dict):\n",
    "        \n",
    "        self.scalers = scalers\n",
    "        self.record_name = record_name\n",
    "        self.graphs_path = data_path / 'graphs'\n",
    "\n",
    "        # Nodes of the trips, by trip_id\n",
    "        self.nodes_of_trips = load_trip_idx_list(self.graphs_path)\n",
    "        \n",
    "        # Which day?\n",
    "        day = name_to_day(record_name)[0]\n",
    "        \n",
    "        # Load and filter (by available bins) delays\n",
    "        df = load_delays(record_name,delays_path)\n",
    "        df = self.filter_delays(df,dt=1/2)\n",
    "\n",
    "        # Training data\n",
    "        self.bin_codes = df['bin_code'].to_numpy()\n",
    "        self.bin_code = None\n",
    "        \n",
    "        self.trip_ids = df.index.to_numpy()\n",
    "\n",
    "        self.secs = scalers['sec'].transform(\n",
    "            torch.tensor(df['trip_start'].to_numpy(),dtype=torch.float32).unsqueeze(-1)\n",
    "        )\n",
    "        \n",
    "        day_tensor = torch.tensor([[day]], dtype=torch.float32)\n",
    "        self.days = scalers['day'].transform(day_tensor) * torch.ones_like(self.secs)\n",
    "        \n",
    "        self.delays = scalers['delay'].transform(\n",
    "            torch.tensor(df['delay'].to_numpy(),dtype=torch.float32).unsqueeze(-1)\n",
    "        )\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        trip_id = self.trip_ids[idx]\n",
    "        trip_nodes = self.nodes_of_trips[trip_id]\n",
    "\n",
    "        sec = self.secs[idx]\n",
    "        day = self.days[idx]\n",
    "        delay = self.delays[idx]\n",
    "        \n",
    "        if self.bin_codes[idx] != self.bin_code:\n",
    "            self.bin_code = self.bin_codes[idx]\n",
    "\n",
    "            # Load the graph\n",
    "            self.g = load_graph(\n",
    "                self.bin_code, \n",
    "                dt=1/2, \n",
    "                record_name=self.record_name, \n",
    "                graphs_path=self.graphs_path\n",
    "            )\n",
    "            self.x = self.scalers['x'].transform(self.g.x)\n",
    "            self.edge_attr = self.scalers['edge_attr'].transform(self.g.edge_attr)\n",
    "            self.edge_index = self.g.edge_index\n",
    "\n",
    "        return {\n",
    "            \"x\": self.x,\n",
    "            \"edge_index\": self.edge_index,\n",
    "            \"edge_attr\": self.edge_attr,\n",
    "            \"trip_nodes\": trip_nodes,\n",
    "            \"day\": day,\n",
    "            \"sec\": sec,\n",
    "            \"delay\": delay,\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trip_ids)\n",
    "\n",
    "    def filter_delays(self, df:pd.DataFrame, dt=1/2):\n",
    "        bin_codes = available_bin_codes(\n",
    "            self.record_name, self.graphs_path\n",
    "        )\n",
    "        bins = np.arange(0,24+dt,dt)\n",
    "        bins *= 60*60\n",
    "\n",
    "        df['bin'] = pd.cut(df['trip_start'], bins=bins, right=False)\n",
    "        df['bin_code'] = df['bin'].cat.codes\n",
    "        return df[df['bin_code'].isin(bin_codes)].sort_values('bin_code') # .groupby('bin_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fa316a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = load_scalers(data_path)\n",
    "dataset = TripDataset(\n",
    "    record_name='20251011',\n",
    "    data_path=data_path,\n",
    "    scalers=scalers\n",
    ")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3884c788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8884 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8884/8884 [00:01<00:00, 5138.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d93b908",
   "metadata": {},
   "source": [
    "# Full graph cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, record_name, data_path:Path, scalers:dict):\n",
    "        \n",
    "        self.scalers = scalers\n",
    "        self.record_name = record_name\n",
    "        self.graphs_path = data_path / 'graphs'\n",
    "\n",
    "        # Load graphs for the record\n",
    "        self.load_graph_cache() # before filtering delays!!!\n",
    "        \n",
    "        # Nodes of the trips, by trip_id\n",
    "        self.nodes_of_trips = load_trip_idx_list(self.graphs_path)\n",
    "        \n",
    "        # Which day?\n",
    "        day = name_to_day(record_name)[0]\n",
    "        \n",
    "        # Load and filter (by available bins) delays\n",
    "        df = load_delays(record_name,delays_path)\n",
    "        df = self.filter_delays(df,dt=1/2)\n",
    "\n",
    "        # Training data\n",
    "        self.bin_codes = df['bin_code'].to_numpy()\n",
    "        self.trip_ids = df.index.to_numpy()\n",
    "\n",
    "        self.secs = scalers['sec'].transform(\n",
    "            torch.tensor(df['trip_start'].to_numpy(),dtype=torch.float32).unsqueeze(-1)\n",
    "        )\n",
    "        \n",
    "        day_tensor = torch.tensor([[day]], dtype=torch.float32)\n",
    "        self.days = scalers['day'].transform(day_tensor) * torch.ones_like(self.secs)\n",
    "        \n",
    "        self.delays = scalers['delay'].transform(\n",
    "            torch.tensor(df['delay'].to_numpy(),dtype=torch.float32).unsqueeze(-1)\n",
    "        )\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        g = self.g_cache[self.bin_codes[idx]]\n",
    "\n",
    "        data = Data(\n",
    "            x=g.x,\n",
    "            edge_index=g.edge_index,\n",
    "            edge_attr=g.edge_attr,\n",
    "            y=self.delays[idx],\n",
    "            day=self.days[idx],\n",
    "            sec=self.secs[idx],\n",
    "            trip_nodes=self.nodes_of_trips[self.trip_ids[idx]]\n",
    "        )\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trip_ids)\n",
    "\n",
    "\n",
    "    def load_graph_cache(self):\n",
    "        self.g_cache = {}\n",
    "        for f in (self.graphs_path / self.record_name).iterdir():\n",
    "            if f.is_file() and f.name.startswith(\"graph_bin_\") and f.suffix == \".pt\":\n",
    "                bin_code = int(f.stem.replace(\"graph_bin_\", \"\"))\n",
    "                g = torch.load(f, weights_only=False)\n",
    "                g.x = self.scalers['x'].transform(g.x)\n",
    "                g.edge_attr = self.scalers['edge_attr'].transform(g.edge_attr)\n",
    "                self.g_cache[bin_code] = g\n",
    "            \n",
    "\n",
    "    def filter_delays(self, df:pd.DataFrame, dt=1/2):\n",
    "        bins = np.arange(0,24+dt,dt)\n",
    "        bins *= 60*60\n",
    "\n",
    "        df['bin'] = pd.cut(df['trip_start'], bins=bins, right=False)\n",
    "        df['bin_code'] = df['bin'].cat.codes\n",
    "        return df[df['bin_code'].isin(self.g_cache.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1224b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = load_scalers(data_path)\n",
    "dataset = TripDataset(\n",
    "    record_name='20251011',\n",
    "    data_path=data_path,\n",
    "    scalers=scalers\n",
    ")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ae32daa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8884/8884 [00:04<00:00, 2084.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb6bf5",
   "metadata": {},
   "source": [
    "# Train???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4d6f3641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EndOfTripDelay(\n",
       "  (GCN): GCNWithEdge(\n",
       "    (convs): ModuleList(\n",
       "      (0): NNConv(7, 32, aggr=mean, nn=Sequential(\n",
       "        (0): Linear(in_features=2, out_features=224, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=224, out_features=224, bias=True)\n",
       "      ))\n",
       "      (1): NNConv(32, 16, aggr=mean, nn=Sequential(\n",
       "        (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      ))\n",
       "    )\n",
       "  )\n",
       "  (MLP): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=18, out_features=2, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EndOfTripDelay(\n",
    "    in_dim=7,\n",
    "    gcn_dims=[32],\n",
    "    edge_attr_dim=2,\n",
    "    embd_dim=16,\n",
    "    mlp_dims=[2],\n",
    "    out_dim=1\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cbc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(loader):\n",
    "        # Move batch to device\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        # Assume your model accepts x, edge_index, edge_attr, trip_nodes, day, sec\n",
    "        pred = model(\n",
    "            batch.x,\n",
    "            batch.edge_index,\n",
    "            batch.edge_attr,\n",
    "            batch.trip_nodes,\n",
    "            batch.day,\n",
    "            batch.sec\n",
    "        )\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(pred, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss/len(loader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
